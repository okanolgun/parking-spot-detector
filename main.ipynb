{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23823530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from util import get_parking_spots_bboxes, empty_or_not\n",
    "# importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = './mask_1920_1080.png'\n",
    "video_path = './data/parking_1920_1080.mp4' \n",
    "# mask.png and video.mp4 is already in our data set and our project directory. \n",
    "\n",
    "mask = cv2.imread(mask, 0)\n",
    "# we read our mask png and turned it to a numpy array\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "# we captured our videp.mp4 and took it to a frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5263c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_components = cv2.connectedComponentsWithStats(mask, 4, cv2.CV_32S)\n",
    "# we getting the connected componens with the mask.png \n",
    "# 4 or 8: used for components with 4 or 8 connections. \n",
    "# 4 only considers up, down, left and right neighbors\n",
    "# cv_325 is a return type of our data\n",
    "\n",
    "spots = get_parking_spots_bboxes(connected_components)\n",
    "# using the method in the util.py class\n",
    "# for gettin the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_diff(im1, im2):\n",
    "    return np.abs(np.mean(im1) - np.mean(im2))\n",
    "# this function calculates the average brightness difference between two images \n",
    "# simple and effective method to understand how different two images are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2241711",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 30 # operation will be performed every 30th frame of the video\n",
    "spots_status = [None for j in spots] # a list that holding the parking spots situations (empty or not)\n",
    "diffs = [None for j in spots] # list that keeps the brightness differences \n",
    "previous_frame = None # holding the previous frame for comparison \n",
    "frame_nmr = 0 # frame number\n",
    "ret = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed9d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "while ret: # loop continues as the video is processed frame by frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret or frame is None:\n",
    "        break\n",
    "\n",
    "    if frame_nmr % step == 0 and previous_frame is not None:\n",
    "        for spot_indx, spot in enumerate(spots):\n",
    "            x1, y1, w, h = spot\n",
    "            spot_crop = frame[y1:y1 + h, x1:x1 + w, :]\n",
    "            diffs[spot_indx] = calc_diff(spot_crop, previous_frame[y1:y1 + h, x1:x1 + w, :])\n",
    "        # In this for loop, we can actually see the relationship between artificial neural networks and mathematics. \n",
    "        # we calculate the coordinate difference for each frame one by one. \n",
    "        # The difference is calculated at each step (30th frame).\n",
    "        # spot_crop: Crop of each parking area (with coordinates obtained from the mask) from the current frame in the video.\n",
    "        # calc_diff(): Calculates the brightness difference between the previous and current frames of the parking area and saves it in the diffs list.\n",
    "\n",
    "        print([diffs[j] for j in np.argsort(diffs)][::-1])\n",
    "        # plt.figure()\n",
    "        # plt.hist([diffs[j] / np.amax() for j in np.argsort(diffs)][::-1])\n",
    "        # if frame_nmr == 300:\n",
    "        #     plt.show()\n",
    "\n",
    "    if frame_nmr % step == 0:\n",
    "        if previous_frame is None:\n",
    "            arr_ = range(len(spots))\n",
    "        else:\n",
    "            arr_ = [j for j in range(len(diffs)) if diffs[j] / np.amax(diffs) > 0.4]\n",
    "        for spot_indx in arr_:\n",
    "            spot = spots[spot_indx]\n",
    "            x1, y1, w, h = spot\n",
    "            spot_crop = frame[y1:y1+h, x1:x1+w, :]\n",
    "            spot_status = empty_or_not(spot_crop)\n",
    "            spots_status[spot_indx] = spot_status\n",
    "        # arr_: control list that update the parking slots according to difference ratio \n",
    "        # empty_or_not(): checking every parking slot that if it is empty or not and adding to spots_status list\n",
    "\n",
    "    if frame_nmr % step ==0:\n",
    "        previous_frame = frame.copy()\n",
    "\n",
    "    for spot_indx, spot in enumerate(spots):\n",
    "        spot_status = spots_status[spot_indx]\n",
    "        x1, y1, w, h = spots[spot_indx]\n",
    "\n",
    "        if spot_status:\n",
    "            frame = cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)\n",
    "        else:\n",
    "            frame = cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 0, 255), 2)\n",
    "        # the status of parking spaces (empty/occupied) is marked with green or red rectangles\n",
    "\n",
    "    cv2.rectangle(frame, (80,20), (550, 80), (0,0,0), -1)\n",
    "\n",
    "    cv2.putText(frame, 'Avaible spots: {} / {}'.format(str(sum(spots_status)), str(len(spots_status))), (100,60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "    cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_nmr = frame_nmr + 1\n",
    "    # shows the parking slots in the screen. we can see the empty parking slots' numbers \n",
    "    # we can see the video with openCV, and if the user press the q button, it will stop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a68db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# and we released all the parking slots and closed all windows"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
