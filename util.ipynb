{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304cab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "EMPTY = True\n",
    "NOT_EMPTY = False\n",
    "\n",
    "MODEL = pickle.load(open(\"./model/model.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b0105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_or_not(spot_bgr):\n",
    "\n",
    "    flat_data = []\n",
    "\n",
    "    img_resized = resize(spot_bgr, (15, 15, 3))\n",
    "    flat_data.append(img_resized.flatten())\n",
    "    flat_data = np.array(flat_data)\n",
    "\n",
    "    y_output = MODEL.predict(flat_data)\n",
    "\n",
    "    if y_output == 0:\n",
    "        return EMPTY\n",
    "    else:\n",
    "        return NOT_EMPTY\n",
    "\n",
    "# empty or not (spot_bgr):\n",
    "# This function takes an image of a parking area and predicts \n",
    "# whether this area is empty or occupied. \n",
    "# It uses a ready-made model for this prediction.\n",
    "\n",
    "# spot_bgr : image of parking lot\n",
    "# img_resized : we make the parking lot smaller. because I want our model to work faster.\n",
    "# img_resized_flatten() : we converted the resized image into a single vector. we made it suitable for the input format of the model.\n",
    "# if the estimate is 0, the parking lot is empty. if it is 1, the parking lot is full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e5864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parking_spots_bboxes(connected_components):\n",
    "    (totalLabels, label_ids, values, centroid) = connected_components\n",
    "\n",
    "    slots = []\n",
    "    coef = 1\n",
    "    for i in range(1, totalLabels):\n",
    "\n",
    "        # extract the coordinate points\n",
    "        x1 = int(values[i, cv2.CC_STAT_LEFT] * coef)\n",
    "        y1 = int(values[i, cv2.CC_STAT_TOP] * coef)\n",
    "        w = int(values[i, cv2.CC_STAT_WIDTH] * coef)\n",
    "        h = int(values[i, cv2.CC_STAT_HEIGHT] * coef)\n",
    "\n",
    "        slots.append([x1, y1, w, h])\n",
    "\n",
    "    return slots\n",
    "\n",
    "# get_parking_spots_bboxes(connected_components):\n",
    "# This function retrieves the boundary boxes of \n",
    "# parking spaces from connected components in the image.\n",
    "\n",
    "# connected_components: Four different sets of information \n",
    "# returned by OpenCV's connectedComponentsWithStats \n",
    "#\n",
    "# the loop iterates as many times as totalLabels. \n",
    "# since the first component (index 0) represents the background, the loop starts from 1.\n",
    "#\n",
    "# we create a list that returns the bounding boxes of parking spaces \n",
    "# (in the format [x1, y1, w, h]). these bounding boxes represent \n",
    "# the location and size of each parking space."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
